{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM9B6s/mtfzj/A2jdnGPsdS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Tokenization with nltk**"],"metadata":{"id":"bbv4lcjxALzO"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBjmYIqo0SQt","executionInfo":{"status":"ok","timestamp":1718037354401,"user_tz":-330,"elapsed":3537,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"5a37d407-8682-42c0-99d3-960e23150693"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Tokens : ['I', 'am', 'attending', 'mky', 'NLP', 'Final', 'Practical', 'Session', '.']\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","\n","text = \"I am attending mky NLP Final Practical Session.\"\n","tokens = nltk.word_tokenize(text)\n","\n","print(\"Tokens :\", tokens)"]},{"cell_type":"markdown","source":["**Stemming with nltk**"],"metadata":{"id":"O5Lf-9S-AVSc"}},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","\n","ps = PorterStemmer()\n","words = ['run', 'running', 'runner', 'ran']\n","\n","stemmed_words = [ps.stem(word) for word in words]\n","\n","print('Stemmed Words :', stemmed_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cm1LEA__5Xq2","executionInfo":{"status":"ok","timestamp":1718037355498,"user_tz":-330,"elapsed":2,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"2f361015-e9f7-4dff-9dae-1ce1c672fa01"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Stemmed Words : ['run', 'run', 'runner', 'ran']\n"]}]},{"cell_type":"markdown","source":["**Lemmatization with nltk**"],"metadata":{"id":"pV-Q6tr5AZrl"}},{"cell_type":"code","source":["nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","\n","lemmatizer = WordNetLemmatizer()\n","words = ['dogs', 'cats', 'running', 'ate']\n","\n","lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n","\n","print('Lemmatized Words :', lemmatized_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGaKuMvG5wPl","executionInfo":{"status":"ok","timestamp":1718037373948,"user_tz":-330,"elapsed":2639,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"8c591bf4-dd09-4730-b4f7-dd3a0eeee352"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Lemmatized Words : ['dog', 'cat', 'running', 'ate']\n"]}]},{"cell_type":"markdown","source":["**POS tagging with nltk**"],"metadata":{"id":"FzRF-g5JAf69"}},{"cell_type":"code","source":["nltk.download('averaged_perceptron_tagger')\n","\n","text = \"I am attending mky NLP Final Practical Session.\"\n","\n","tokens = nltk.word_tokenize(text)\n","pos_tags = nltk.pos_tag(tokens)\n","\n","print('POS Tags:', pos_tags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"blEeWUc46K8b","executionInfo":{"status":"ok","timestamp":1718037390402,"user_tz":-330,"elapsed":692,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"5fb88002-6ccd-4a02-9549-08c50e27fcea"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["POS Tags: [('I', 'PRP'), ('am', 'VBP'), ('attending', 'VBG'), ('mky', 'NN'), ('NLP', 'NNP'), ('Final', 'NNP'), ('Practical', 'NNP'), ('Session', 'NNP'), ('.', '.')]\n"]}]},{"cell_type":"markdown","source":["**Sentiment analysis with nltk**"],"metadata":{"id":"1JbuEEPPAjnh"}},{"cell_type":"code","source":["nltk.download('vader_lexicon')\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","\n","sia = SentimentIntensityAnalyzer()\n","text = \"I am attending mky NLP Final Practical Session.\"\n","\n","sentiment_scores = sia.polarity_scores(text)\n","\n","print(\"Sentiment Scores :\", sentiment_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yJPJTOaL6Zzj","executionInfo":{"status":"ok","timestamp":1718037413761,"user_tz":-330,"elapsed":469,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"d6164ee4-6220-487b-e599-93e0e8fd59fe"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment Scores : {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]}]},{"cell_type":"markdown","source":["**Frequency distribution with nltk**"],"metadata":{"id":"YU9ImDn1AoKf"}},{"cell_type":"code","source":["from nltk import FreqDist\n","\n","text = \"I am attending mky NLP Final Practical Session.\"\n","\n","tokens = nltk.word_tokenize(text)\n","fdist = FreqDist(tokens)\n","\n","print(\"Frequency Distribution :\", fdist.most_common())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P3SonGCw85DZ","executionInfo":{"status":"ok","timestamp":1718037425804,"user_tz":-330,"elapsed":512,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"bea5272e-f03b-4ab7-a74a-f9c778787bae"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Frequency Distribution : [('I', 1), ('am', 1), ('attending', 1), ('mky', 1), ('NLP', 1), ('Final', 1), ('Practical', 1), ('Session', 1), ('.', 1)]\n"]}]},{"cell_type":"markdown","source":["**StopWords with nltk**"],"metadata":{"id":"p8i4lbDLAs7R"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","nltk.download('stopwords')\n","\n","text = \"I am attending mky NLP Final Practical Session.\"\n","\n","stop_words = set(stopwords.words(\"english\"))\n","tokens = nltk.word_tokenize(text)\n","\n","filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n","\n","print(\"Filtered Tokens:\", filtered_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ct4R7Vvt9Nih","executionInfo":{"status":"ok","timestamp":1718037439798,"user_tz":-330,"elapsed":469,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"82b415c9-11a6-4b63-d2b7-1475e2b39ed6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered Tokens: ['attending', 'mky', 'NLP', 'Final', 'Practical', 'Session', '.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"markdown","source":["**Named-entity-recognition with nltk**"],"metadata":{"id":"crLxdZcqAvA-"}},{"cell_type":"code","source":["nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","text = \"I am attending mky NLP Final Practical Session.\"\n","tokens = nltk.word_tokenize(text)\n","pos_tags = nltk.pos_tag(tokens)\n","chunks = nltk.ne_chunk(pos_tags)\n","\n","for chunk in chunks:\n","  if hasattr(chunk, 'label'):\n","    print(chunk.label(), ' '.join(c[0] for c in chunk))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24eDlZWx-iGY","executionInfo":{"status":"ok","timestamp":1718037456044,"user_tz":-330,"elapsed":606,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"925d9c7e-0dc0-426d-f13d-4b22c5953882"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]},{"output_type":"stream","name":"stdout","text":["ORGANIZATION NLP Final Practical Session\n"]}]},{"cell_type":"markdown","source":["**Sentence tokenization with nltk**"],"metadata":{"id":"bzHctqlYAyyW"}},{"cell_type":"code","source":["text = 'I am attending mky NLP Final Practical Session.'\n","\n","sentences = nltk.sent_tokenize(text)\n","\n","print(\"Sentences :\",sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ymY9716K_Zsf","executionInfo":{"status":"ok","timestamp":1718037480692,"user_tz":-330,"elapsed":745,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"f6cf74bb-cc8c-4eab-b9b9-80433b0964b6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentences : ['I am attending mky NLP Final Practical Session.']\n"]}]},{"cell_type":"markdown","source":["**Concordance with nltk**"],"metadata":{"id":"cl9yM02fA4cf"}},{"cell_type":"code","source":["nltk.download('all')\n","from nltk.book import text1\n","\n","concordance_list = text1.concordance_list('monstrous')\n","\n","for e in concordance_list:\n","  print(e.line)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3MIduyLdBotX","executionInfo":{"status":"ok","timestamp":1718037543607,"user_tz":-330,"elapsed":46607,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"455a5a6f-46c0-4206-db58-e7c5c6e3177e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n","[nltk_data]    |       to-date!\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Package punkt is already up-to-date!\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Package stopwords is already up-to-date!\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Package vader_lexicon is already up-to-date!\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Package wordnet is already up-to-date!\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Package words is already up-to-date!\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]},{"output_type":"stream","name":"stdout","text":["*** Introductory Examples for the NLTK Book ***\n","Loading text1, ..., text9 and sent1, ..., sent9\n","Type the name of the text or sentence to view it.\n","Type: 'texts()' or 'sents()' to list the materials.\n","text1: Moby Dick by Herman Melville 1851\n","text2: Sense and Sensibility by Jane Austen 1811\n","text3: The Book of Genesis\n","text4: Inaugural Address Corpus\n","text5: Chat Corpus\n","text6: Monty Python and the Holy Grail\n","text7: Wall Street Journal\n","text8: Personals Corpus\n","text9: The Man Who Was Thursday by G . K . Chesterton 1908\n","ong the former , one was of a most monstrous size . ... This came towards us , \n","ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n","ll over with a heathenish array of monstrous clubs and spears . Some were thick\n","d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n","that has survived the flood ; most monstrous and most mountainous ! That Himmal\n","they might scout at Moby Dick as a monstrous fable , or still worse and more de\n","th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n","ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n","ere to enter upon those still more monstrous stories of them which are to be fo\n","ght have been rummaged out of this monstrous cabinet there is no telling . But \n","of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"]}]},{"cell_type":"markdown","source":["**Collocatioin with nltk**"],"metadata":{"id":"J2drCpmfA-lj"}},{"cell_type":"code","source":["collactions = text1.collocation_list()\n","print('Collactions :', collactions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzu-9tc8CfGQ","executionInfo":{"status":"ok","timestamp":1718037544405,"user_tz":-330,"elapsed":800,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"74e9b9e1-4293-4a3c-f024-04baad5b28a2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collactions : [('Sperm', 'Whale'), ('Moby', 'Dick'), ('White', 'Whale'), ('old', 'man'), ('Captain', 'Ahab'), ('sperm', 'whale'), ('Right', 'Whale'), ('Captain', 'Peleg'), ('New', 'Bedford'), ('Cape', 'Horn'), ('cried', 'Ahab'), ('years', 'ago'), ('lower', 'jaw'), ('never', 'mind'), ('Father', 'Mapple'), ('cried', 'Stubb'), ('chief', 'mate'), ('white', 'whale'), ('ivory', 'leg'), ('one', 'hand')]\n"]}]},{"cell_type":"markdown","source":["**N-gram with nltk**"],"metadata":{"id":"cUxCraOFBCJX"}},{"cell_type":"code","source":["from nltk import bigrams\n","from nltk.book import text1\n","\n","bi_grams = list(bigrams(text1))\n","\n","print(\"Bigrams :\", bi_grams[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"grqpHColCoO0","executionInfo":{"status":"ok","timestamp":1718037544405,"user_tz":-330,"elapsed":2,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"2579c40f-874e-4d02-a9ed-ee6dc57086c9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Bigrams : [('[', 'Moby'), ('Moby', 'Dick'), ('Dick', 'by'), ('by', 'Herman'), ('Herman', 'Melville'), ('Melville', '1851'), ('1851', ']'), (']', 'ETYMOLOGY'), ('ETYMOLOGY', '.'), ('.', '(')]\n"]}]},{"cell_type":"code","source":["from nltk import trigrams\n","from nltk.book import text1\n","\n","tri_grams = list(trigrams(text1))\n","\n","print(\"Bigrams :\", tri_grams[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQr8EFiLEOwS","executionInfo":{"status":"ok","timestamp":1718037551192,"user_tz":-330,"elapsed":461,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"4482354c-e00f-43c7-83a3-480e3e116489"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Bigrams : [('[', 'Moby', 'Dick'), ('Moby', 'Dick', 'by'), ('Dick', 'by', 'Herman'), ('by', 'Herman', 'Melville'), ('Herman', 'Melville', '1851'), ('Melville', '1851', ']'), ('1851', ']', 'ETYMOLOGY'), (']', 'ETYMOLOGY', '.'), ('ETYMOLOGY', '.', '('), ('.', '(', 'Supplied')]\n"]}]},{"cell_type":"markdown","source":["**Wordnet with nltk**"],"metadata":{"id":"jRaYNEnuBLLp"}},{"cell_type":"code","source":["from nltk.corpus import wordnet\n","\n","synsets = wordnet.synsets('car')\n","\n","for synset in synsets:\n","  print('Sysnet Name :', synset.name())\n","  print('Definition :', synset.definition())\n","  print('Examples :', synset.examples())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ivWYFZ7QEX6U","executionInfo":{"status":"ok","timestamp":1718037573473,"user_tz":-330,"elapsed":457,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"a129cad7-f55b-408b-9736-ed79376f83a3"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Sysnet Name : car.n.01\n","Definition : a motor vehicle with four wheels; usually propelled by an internal combustion engine\n","Examples : ['he needs a car to get to work']\n","Sysnet Name : car.n.02\n","Definition : a wheeled vehicle adapted to the rails of railroad\n","Examples : ['three cars had jumped the rails']\n","Sysnet Name : car.n.03\n","Definition : the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n","Examples : []\n","Sysnet Name : car.n.04\n","Definition : where passengers ride up and down\n","Examples : ['the car was on the top floor']\n","Sysnet Name : cable_car.n.01\n","Definition : a conveyance for passengers or freight on a cable railway\n","Examples : ['they took a cable car to the top of the mountain']\n"]}]},{"cell_type":"markdown","source":["**Word-similarity with nltk**"],"metadata":{"id":"vT2eB1uPBPW6"}},{"cell_type":"code","source":["word1 = wordnet.synset('car.n.01')\n","word2 = wordnet.synset('bus.n.01')\n","\n","similarity = word1.wup_similarity(word2)\n","\n","print(f'Similarity between {word1} and {word2} is {similarity}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwtPY6I3E2GK","executionInfo":{"status":"ok","timestamp":1718037586820,"user_tz":-330,"elapsed":2,"user":{"displayName":"Arindam Sahoo","userId":"00690010695865001987"}},"outputId":"a257e568-81ca-4541-e447-f28ee6d04f4a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity between Synset('car.n.01') and Synset('bus.n.01') is 0.6666666666666666\n"]}]}]}